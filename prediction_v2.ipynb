{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1877919",
   "metadata": {},
   "source": [
    "# KAGGLE COMPETITON AUEB 2021-2022\n",
    "## Link Citation Prediction\n",
    "##### Link prediction is the problem of predicting the existence of a link between two entities in a network.\n",
    "\n",
    "The problem of link prediction has recently attracted a lot of attention in many domains. For instance, in social networks, one may be interested in predicting friendship links among users, while in biology, predicting interactions between genes and proteins is of paramount importance.\n",
    "\n",
    "In this challenge, you will deal with the problem of predicting whether a research paper cites another research paper. You are given a citation network consisting of several thousands of research papers, along with their abstracts and their list of authors. The pipeline that is typically followed to deal with the problem is similar to the one applied in any classification problem; the goal is to use edge information to learn the parameters of a classifier and then to use the classifier to predict whether two nodes are linked by an edge or not.\n",
    "\n",
    "Next, we also provide a simple approach, on which you can work. The key component is how we create our training and test data. For training, you may first create a numpy array of zeros with 2m rows and n columns (where m is the number of edges in the edgelist file, and n the number of desired features). We then need to populate this array to create the training features. A way to do that is to iterate over all edges in the edgelist file, and if we want to have 3 features: we get the degree of the first node of the edge as the 1st column, the degree of the 2nd node of the edge as the 2nd column and their sum as the 3rd column. For the remaining m rows, we select randomly nodes and get their degrees and sum as features as well. Now we have our matrix for training. We also need to create the y classes. We create a vector of zeros with size 2m. The first m elements represent the edges that are present in the edgelist. Thus we make them 1. The remaining need to be 0, as they represent non-existing edges. We are now ready to give the features and classes to a scikitlearn classifier via the 'fit' method. Afterwards, we only need to create a similar feature matrix for the test file. We then need the probabilities of our predictions. Remember to get the probabilities only for the positive class. Please, check the 'submissionsrandom' file to check if the format matches your output. The 1st column in the submissions file represents an id integer of the edges in test file. 0 points to the first edge of the test file and so on. You are now ready to submit!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b42235",
   "metadata": {},
   "source": [
    "\t---\n",
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13d01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132f1d4",
   "metadata": {},
   "source": [
    "\t---\n",
    "## Data Acquisition\n",
    "#### Read Edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c331146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n"
     ]
    }
   ],
   "source": [
    "# Create a graph\n",
    "G = nx.read_edgelist('data/edgelist.txt', delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "nodes = list(G.nodes())\n",
    "\n",
    "num_of_nodes = G.number_of_nodes()\n",
    "num_of_edges = G.number_of_edges()\n",
    "\n",
    "print('Number of nodes:', num_of_nodes)\n",
    "print('Number of edges:', num_of_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b5496e",
   "metadata": {},
   "source": [
    "##### Read Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7820b0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read the abstract of each paper\n",
    "abstracts = dict()\n",
    "\n",
    "with open('data/abstracts.txt', 'r', encoding = \"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        node, abstract = line.split('|--|')\n",
    "        \n",
    "        abstracts[int(node)] = abstract\n",
    "\n",
    "for node in abstracts:\n",
    "    abstracts[node] = set(abstracts[node].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c794a",
   "metadata": {},
   "source": [
    "##### Read Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1598fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = dict()\n",
    "with open('data/authors.txt', 'r', encoding = \"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        node, author = line.split('|--|')\n",
    "        \n",
    "        authors[int(node)] = author.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1d229",
   "metadata": {},
   "source": [
    "\t---\n",
    "#### DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141638c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list_1 = []\n",
    "node_list_2 = []\n",
    "\n",
    "for i in G.edges:\n",
    "  node_list_1.append(i[0])\n",
    "  node_list_2.append(i[1])\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'node_1': node_list_1, 'node_2': node_list_2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c3e09",
   "metadata": {},
   "source": [
    "\t---\n",
    "## Data Preparation\n",
    "#### Baseline Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8687c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features:\n",
    "# (1) sum of number of unique terms of the two nodes' abstracts\n",
    "# (2) absolute value of difference of number of unique terms of the two nodes' abstracts\n",
    "# (3) number of common terms between the abstracts of the two nodes\n",
    "\n",
    "x = np.zeros((2*num_of_edges, 3))\n",
    "y = np.zeros(2*num_of_edges)\n",
    "\n",
    "for i, edge in enumerate(G.edges()):\n",
    "    # an edge\n",
    "    x[i,0] = len(abstracts[edge[0]]) + len(abstracts[edge[1]])\n",
    "    x[i,1] = abs(len(abstracts[edge[0]]) - len(abstracts[edge[1]]))\n",
    "    x[i,2] = len(abstracts[edge[0]].intersection(abstracts[edge[1]]))\n",
    "\n",
    "    y[i] = 1\n",
    "\n",
    "    # a randomly generated pair of nodes\n",
    "    n1 = randint(0, num_of_nodes-1)\n",
    "    n2 = randint(0, num_of_nodes-1)\n",
    "    x[num_of_edges+i,0] = len(abstracts[n1]) + len(abstracts[n2])\n",
    "    x[num_of_edges+i,1] = abs(len(abstracts[n1]) - len(abstracts[n2]))\n",
    "    x[num_of_edges+i,2] = len(abstracts[n1].intersection(abstracts[n2]))\n",
    "    \n",
    "    y[num_of_edges+i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Data + Common Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f2b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features:\n",
    "# (1) sum of number of unique terms of the two nodes' abstracts\n",
    "# (2) absolute value of difference of number of unique terms of the two nodes' abstracts\n",
    "# (3) number of common terms between the abstracts of the two nodes\n",
    "# (4) number of common Authors between the Author List of the two nodes\n",
    "\n",
    "x = np.zeros((2*num_of_edges, 4))\n",
    "y = np.zeros(2*num_of_edges)\n",
    "\n",
    "for i, edge in enumerate(G.edges()):\n",
    "    # an edge\n",
    "    x[i,0] = len(abstracts[edge[0]]) + len(abstracts[edge[1]])\n",
    "    x[i,1] = abs(len(abstracts[edge[0]]) - len(abstracts[edge[1]]))\n",
    "    x[i,2] = len(abstracts[edge[0]].intersection(abstracts[edge[1]]))\n",
    "    x[i,3] = len(set(authors[edge[0]]).intersection(authors[edge[1]]))\n",
    "\n",
    "    y[i] = 1\n",
    "\n",
    "    # a randomly generated pair of nodes\n",
    "    n1 = randint(0, num_of_nodes-1)\n",
    "    n2 = randint(0, num_of_nodes-1)\n",
    "    x[num_of_edges+i,0] = len(abstracts[n1]) + len(abstracts[n2])\n",
    "    x[num_of_edges+i,1] = abs(len(abstracts[n1]) - len(abstracts[n2]))\n",
    "    x[num_of_edges+i,2] = len(abstracts[n1].intersection(abstracts[n2]))\n",
    "    x[num_of_edges+i,3] = len(set(authors[n1]).intersection(authors[n2]))\n",
    "    \n",
    "    y[num_of_edges+i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48d4c59",
   "metadata": {},
   "source": [
    "\t---\n",
    "#### Shuffle Data and Split into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efbaf0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = shuffle(x, y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df56206",
   "metadata": {},
   "source": [
    "\t---\n",
    "## Models\n",
    "##### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "381a991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5558905303876713%\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_pred, y_test)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dd7ba",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8ca8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use logistic regression to predict if two nodes are linked by an edge\n",
    "clf = LogisticRegression(solver='liblinear',random_state=54)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f5eab",
   "metadata": {},
   "source": [
    "##### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dda9bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef881db3",
   "metadata": {},
   "source": [
    "##### Ada-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "790af812",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(n_estimators=10, learning_rate=1)\n",
    "\n",
    "model = abc.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84448239",
   "metadata": {},
   "source": [
    "\t---\n",
    "## Metrics\n",
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7201781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7226939547014715%\n"
     ]
    }
   ],
   "source": [
    "y_predictions = []\n",
    "for i in y_pred: \n",
    "    if i >= 0.5: \n",
    "        y_predictions.append(1)\n",
    "    else:\n",
    "        y_predictions.append(0)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_predictions, y_test)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aafe2d",
   "metadata": {},
   "source": [
    "\t---\n",
    "## Accuracy Score\n",
    "\n",
    "#### Baseline Data:\n",
    "\n",
    "\tGaussian Naive Bayes: 0.660876445571067%\n",
    "\n",
    "\tLogistic Regression:\n",
    "\t\tRS 34: 0.7141752964405159% (Baseline)\n",
    "\t\tRS 54: 0.7129389828894205%\n",
    "\n",
    "\tLinear Regression: 0.7173146170724828%\n",
    "\n",
    "\tAda-Boost:\n",
    "\t\t10 E, 1 lR: 0.7015484140386609%\n",
    "\t\t50 E, 1 lR: 0.7171332910849888%\n",
    "\t\t10 E, 5 lR: 0.3140895787009733%\n",
    "\t\t50 E, 5 lR: 0.3140895787009733%\n",
    "\n",
    "#### Baseline Data + Common Authors:\n",
    "\n",
    "\tGaussian Naive Bayes: 0.5558905303876713%\n",
    "\n",
    "\tLogistic Regression:\n",
    "\t\tRS 34: 0.7238331947441106%\n",
    "\t\tRS 54: 0.7226939547014715%\n",
    "\n",
    "\tLinear Regression: 0.7215931777470888%\n",
    "\n",
    "\tAda-Boost:\n",
    "\t\t10 E, 1 lR: 0.7105487766906359%\n",
    "\t\t50 E, 1 lR: 0.7245456776646678%\n",
    "\t\t10 E, 5 lR: 0.3146756829029741%\n",
    "\t\t50 E, 5 lR: 0.3146756829029741%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
