{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "\n",
    "from scipy import spatial\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(text_a, text_b):\n",
    "    model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    return 1 - spatial.distance.cosine(get_vector(model, text_a), get_vector(model, text_b))\n",
    "\n",
    "def preprocess(s):\n",
    "    return [i.lower() for i in s]\n",
    "\n",
    "def get_vector(model, s):\n",
    "    print(model.wv.key_to_index())\n",
    "    return np.sum(np.array([model.wv[i] for i in preprocess(s)]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/87/tx5hfcxj00j3r5zhrht5lm440000gn/T/ipykernel_55510/1037836882.py:6: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adjacency_matrix = nx.adjacency_matrix(G)\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist('data/edgelist.txt', delimiter=',', create_using=nx.Graph(), nodetype=int) # read graph\n",
    "nodes = list(G.nodes())\n",
    "num_of_nodes = G.number_of_nodes()\n",
    "num_of_edges = G.number_of_edges()\n",
    "\n",
    "adjacency_matrix = nx.adjacency_matrix(G)\n",
    "\n",
    "\n",
    "abstracts_list = [] #Init List Abstracts\n",
    "with open('data/abstracts.txt', 'r', encoding = \"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        abstracts_list.append(set(line.split('|--|')[1].replace(\"\\n\", \"\").split()))  \n",
    "        \n",
    "authors_list = [] #Init List Authors\n",
    "with open('data/authors.txt', 'r', encoding = \"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        authors_list.append(set(line.split('|--|')[1].replace(\"\\n\", \"\").split(\",\"))) \n",
    "\n",
    "df = pd.DataFrame(data = {'abstracts': abstracts_list, 'authors': authors_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "#### Baseline Data, Common Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = df.to_dict()['abstracts']\n",
    "authors = df.to_dict()['authors']\n",
    "\n",
    "# Features:\n",
    "# (1) sum of number of unique terms of the two nodes' abstracts\n",
    "# (2) absolute value of difference of number of unique terms of the two nodes' abstracts\n",
    "# (3) number of common terms between the abstracts of the two nodes\n",
    "# (4) number of common authors between the authorlists of the two nodes\n",
    "\n",
    "x = np.zeros((2*num_of_edges, 4))\n",
    "y = np.zeros(2*num_of_edges)\n",
    "\n",
    "for i, edge in enumerate(G.edges()):\n",
    "    # an edge\n",
    "    x[i,0] = len(abstracts[edge[0]]) + len(abstracts[edge[1]])\n",
    "    x[i,1] = abs(len(abstracts[edge[0]]) - len(abstracts[edge[1]]))\n",
    "    x[i,2] = len(abstracts[edge[0]].intersection(abstracts[edge[1]]))\n",
    "    x[i,3] = len(authors[edge[0]].intersection(authors[edge[1]]))\n",
    "\n",
    "    y[i] = 1\n",
    "\n",
    "    # a randomly generated pair of nodes\n",
    "    n1 = randint(0, num_of_nodes-1)\n",
    "    n2 = randint(0, num_of_nodes-1)\n",
    "    x[num_of_edges+i,0] = len(abstracts[n1]) + len(abstracts[n2])\n",
    "    x[num_of_edges+i,1] = abs(len(abstracts[n1]) - len(abstracts[n2]))\n",
    "    x[num_of_edges+i,2] = len(abstracts[n1].intersection(abstracts[n2]))\n",
    "    x[num_of_edges+i,3] = len(authors[n1].intersection(authors[n2]))\n",
    "    \n",
    "    y[num_of_edges+i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Data, Common Authors, Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = df.to_dict()['abstracts']\n",
    "authors = df.to_dict()['authors']\n",
    "H = G.to_directed()\n",
    "\n",
    "pagerank = nx.pagerank(H)\n",
    "\n",
    "# Features:\n",
    "# (1) sum of number of unique terms of the two nodes' abstracts\n",
    "# (2) absolute value of difference of number of unique terms of the two nodes' abstracts\n",
    "# (3) number of common terms between the abstracts of the two nodes\n",
    "# (4) number of common authors between the authorlists of the two nodes\n",
    "# (5) pagerank of first node\n",
    "# (6) pagerank of second node\n",
    "\n",
    "x = np.zeros((2*num_of_edges, 6))\n",
    "y = np.zeros(2*num_of_edges)\n",
    "\n",
    "for i, edge in enumerate(G.edges()):\n",
    "    # an edge\n",
    "    x[i,0] = len(abstracts[edge[0]]) + len(abstracts[edge[1]])\n",
    "    x[i,1] = abs(len(abstracts[edge[0]]) - len(abstracts[edge[1]]))\n",
    "    x[i,2] = len(abstracts[edge[0]].intersection(abstracts[edge[1]]))\n",
    "    x[i,3] = len(authors[edge[0]].intersection(authors[edge[1]]))\n",
    "    x[i,4] = pagerank[edge[0]]\n",
    "    x[i,5] = pagerank[edge[1]]\n",
    "\n",
    "    y[i] = 1\n",
    "\n",
    "    # a randomly generated pair of nodes\n",
    "    n1 = randint(0, num_of_nodes-1)\n",
    "    n2 = randint(0, num_of_nodes-1)\n",
    "    x[num_of_edges+i,0] = len(abstracts[n1]) + len(abstracts[n2])\n",
    "    x[num_of_edges+i,1] = abs(len(abstracts[n1]) - len(abstracts[n2]))\n",
    "    x[num_of_edges+i,2] = len(abstracts[n1].intersection(abstracts[n2]))\n",
    "    x[num_of_edges+i,3] = len(authors[n1].intersection(authors[n2]))\n",
    "    x[num_of_edges+i,4] = pagerank[n1]\n",
    "    x[num_of_edges+i,5] = pagerank[n2]\n",
    "    \n",
    "    y[num_of_edges+i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "train_accuracy = []\n",
    "cv_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "train_data = pd.DataFrame(data = {'sum_of_unique_terms': x_train[:,0], 'diff_of_unique_terms': x_train[:,1], 'common_terms': x_train[:,2], 'common_authors': x_train[:,3], 'target': y_train})\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=False)\n",
    "model = LogisticRegression(solver='liblinear',random_state=34)\n",
    "\n",
    "feature_df = train_data.drop('target' ,axis= 1)\n",
    "target_df = train_data[['target']]\n",
    "\n",
    "fold_index = 1\n",
    "for train_index, test_index in kf.split(train_data):\n",
    "    X_train_cv = feature_df.iloc[train_index]\n",
    "    X_test_cv = feature_df.iloc[test_index]\n",
    "    Y_train_cv = target_df.iloc[train_index]\n",
    "    Y_test_cv = target_df.loc[test_index]\n",
    "        \n",
    "    #Train the model\n",
    "    model.fit(X_train_cv, Y_train_cv.values.ravel()) #Training the model\n",
    "\n",
    "\n",
    "    train_pred = model.predict_proba(X_train_cv)\n",
    "    train_pred = train_pred[:,1]\n",
    "\n",
    "    train_pred_fixed = []\n",
    "    for item in train_pred: \n",
    "        if item >= 0.5: \n",
    "            train_pred_fixed.append(1)\n",
    "        else:\n",
    "            train_pred_fixed.append(0)\n",
    "\n",
    "    cv_pred = model.predict_proba(X_test_cv)\n",
    "    cv_pred = cv_pred[:,1]\n",
    "\n",
    "    cv_pred_fixed = []\n",
    "    for item in cv_pred: \n",
    "        if item >= 0.5: \n",
    "            cv_pred_fixed.append(1)\n",
    "        else:\n",
    "            cv_pred_fixed.append(0)\n",
    "\n",
    "    test_pred = model.predict_proba(x_test)\n",
    "    test_pred = test_pred[:,1]\n",
    "\n",
    "    test_pred_fixed = []\n",
    "    for item in test_pred: \n",
    "        if item >= 0.5: \n",
    "            test_pred_fixed.append(1)\n",
    "        else:\n",
    "            test_pred_fixed.append(0)\n",
    "\n",
    "    indexes.append(fold_index)\n",
    "    train_accuracy.append(accuracy_score(Y_train_cv, train_pred_fixed))\n",
    "    cv_accuracy.append(accuracy_score(Y_test_cv, cv_pred_fixed))\n",
    "    test_accuracy.append(accuracy_score(y_test, test_pred_fixed))\n",
    "\n",
    "    print(\"Current Index:\", fold_index)\n",
    "    fold_index += 1\n",
    "\n",
    "plt.plot(indexes, train_accuracy, label=\"Train Data\")\n",
    "plt.plot(indexes, cv_accuracy, label=\"Validate Data\")\n",
    "plt.plot(indexes, test_accuracy, label=\"Test Data\")\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and Write to CSV\n",
    "\n",
    "#### Baseline Data, Common Authors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data. Each sample is a pair of nodes\n",
    "node_pairs = list()\n",
    "with open('data/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        node_pairs.append((int(t[0]), int(t[1])))\n",
    "\n",
    "# Create the test matrix. Use the same 4 features as above\n",
    "X_test = np.zeros((len(node_pairs), 4))\n",
    "for i,node_pair in enumerate(node_pairs):\n",
    "    X_test[i,0] = len(abstracts[node_pair[0]]) + len(abstracts[node_pair[1]])\n",
    "    X_test[i,1] = abs(len(abstracts[node_pair[0]]) - len(abstracts[node_pair[1]]))\n",
    "    X_test[i,2] = len(abstracts[node_pair[0]].intersection(abstracts[node_pair[1]]))\n",
    "    X_test[i,3] = len(authors[node_pair[0]].intersection(authors[node_pair[1]]))\n",
    "\n",
    "print('Size of test matrix:', X_test.shape)\n",
    "\n",
    "X_train, y_train = shuffle(x, y)\n",
    "\n",
    "\n",
    "# START OF MODEL\n",
    "\n",
    "# END OF MODEL\n",
    "\n",
    "print(\"Number of Predictions: \", len(y_pred))\n",
    "\n",
    "# Write predictions to a file\n",
    "predictions = zip(range(len(y_pred)), y_pred)\n",
    "with open(\"submission_common_authors_abc.csv\",\"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Data, Common Authors, Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test matrix: (106692, 6)\n",
      "Number of Predictions:  106692\n",
      "Predictions written to file\n"
     ]
    }
   ],
   "source": [
    "# Read test data. Each sample is a pair of nodes\n",
    "node_pairs = list()\n",
    "with open('data/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        node_pairs.append((int(t[0]), int(t[1])))\n",
    "\n",
    "# Create the test matrix. Use the same 6 features as above\n",
    "X_test = np.zeros((len(node_pairs), 6))\n",
    "for i,node_pair in enumerate(node_pairs):\n",
    "    X_test[i,0] = len(abstracts[node_pair[0]]) + len(abstracts[node_pair[1]])\n",
    "    X_test[i,1] = abs(len(abstracts[node_pair[0]]) - len(abstracts[node_pair[1]]))\n",
    "    X_test[i,2] = len(abstracts[node_pair[0]].intersection(abstracts[node_pair[1]]))\n",
    "    X_test[i,3] = len(authors[node_pair[0]].intersection(authors[node_pair[1]]))\n",
    "    X_test[i,4] = pagerank[node_pair[0]]\n",
    "    X_test[i,5] = pagerank[node_pair[1]]\n",
    "\n",
    "print('Size of test matrix:', X_test.shape)\n",
    "\n",
    "X_train, y_train = shuffle(x, y)\n",
    "\n",
    "\n",
    "# START OF MODEL\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "# END OF MODEL\n",
    "\n",
    "print(\"Number of Predictions: \", len(y_pred))\n",
    "\n",
    "# Write predictions to a file\n",
    "predictions = zip(range(len(y_pred)), y_pred)\n",
    "with open(\"linear_baseline_common_authors_pagerank.csv\",\"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','predicted'])\n",
    "    for row in predictions:\n",
    "        csv_out.writerow(row)\n",
    "\n",
    "print(\"Predictions written to file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6991362289323013%\n"
     ]
    }
   ],
   "source": [
    "x, y = shuffle(x, y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "# Use logistic regression to predict if two nodes are linked by an edge\n",
    "clf = LogisticRegression(solver='liblinear',random_state=34)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "y_predictions = []\n",
    "for i in y_pred: \n",
    "    if i >= 0.5: \n",
    "        y_predictions.append(1)\n",
    "    else:\n",
    "        y_predictions.append(0)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_predictions, y_test)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline Data, Common Authors: 0.7265512529808893%\n",
    "##### Baseline Data, Common Authors, Pagerank: 0.727549461699922%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7559260629549176%\n"
     ]
    }
   ],
   "source": [
    "x, y = shuffle(x, y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "# Use logistic regression to predict if two nodes are linked by an edge\n",
    "clf = LinearRegression()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "y_predictions = []\n",
    "for i in y_pred: \n",
    "    if i >= 0.5: \n",
    "        y_predictions.append(1)\n",
    "    else:\n",
    "        y_predictions.append(0)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_predictions, y_test)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline Data, Common Authors: 0.7235657847019477%\n",
    "##### Baseline Data, Common Authors, Pagerank: 0.776417731117371%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7850297997355205%\n"
     ]
    }
   ],
   "source": [
    "x, y = shuffle(x, y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "# Use logistic regression to predict if two nodes are linked by an edge\n",
    "abc = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "model = abc.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_predictions = []\n",
    "for i in y_pred: \n",
    "    if i >= 0.5: \n",
    "        y_predictions.append(1)\n",
    "    else:\n",
    "        y_predictions.append(0)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_predictions, y_test)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline Data, Common Authors: 0.7058306378645294%\n",
    "##### Baseline Data, Common Authors, Pagerank: 0.7721501598965526% 0.7850297997355205%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_list_2 = []\n",
    "with open('data/abstracts.txt', 'r', encoding = \"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        abstracts_list_2.append(line.split('|--|')[1].replace(\"\\n\", \"\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper 0 - Paper 1 0.8254383206367493\n",
      "Paper 1 - Paper 2 0.7354351282119751\n"
     ]
    }
   ],
   "source": [
    "# test_abstracts = [[word.lower() for word in abstract] for abstract in abstracts[:5]]\n",
    "\n",
    "tmp = abstracts_list_2[:4]\n",
    "\n",
    "fixed = []\n",
    "\n",
    "for abstract in tmp:\n",
    "    fixed.append([word.lower() for word in abstract])\n",
    "\n",
    "model = Word2Vec(fixed, min_count=1)\n",
    "\n",
    "def similarity(text_a, text_b):\n",
    "    return 1 - spatial.distance.cosine(get_vector(model, text_a), get_vector(model, text_b))\n",
    "\n",
    "def preprocess(s):\n",
    "    return [i.lower() for i in s]\n",
    "\n",
    "def get_vector(model, s):\n",
    "    return np.sum(np.array([model.wv[i] for i in preprocess(s)]), axis=0)\n",
    "\n",
    "print(\"Paper 0 - Paper 1\", similarity(fixed[0], fixed[1]))\n",
    "# print(\"Paper 0 - Paper 2\", similarity(tmp[0], tmp[2]))\n",
    "print(\"Paper 1 - Paper 2\", similarity(tmp[1], tmp[2]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
