{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Handwritten Digit Recognition\n",
    "\n",
    "Object recognition is one of the most exciting tasks in the field of Computer Vision. The goal is to detect and identify objects in an image. The most popular dataset in object recognition involves recognizing handwritten digits. In this part of the lab, we will develop a convolutional neural network for classifying handwritten digits using the [Keras](https://keras.io/) library. We will evaluate the neural network on the well-known [MNIST dataset](http://yann.lecun.com/exdb/mnist/). The dataset was created by Yann LeCun, Corinna Cortes and Christopher Burges for evaluating machine learning models. Each instance corresponds to the image of a digit taken from a scanned document. Each image is a 28 by 28 pixel square (784 pixels total), and the digits are normalized in size and centred. There are 10 digits in total (0 to 9). Hence, there are 10 classes in total. The dataset is split into a training set consisting of 60,000 images and a test set of 10,000 images.\n",
    "\n",
    "Keras provides a function for directly loading the MNIST dataset. The dataset is downloaded automatically the first time this function is called and is stored in the disk. Run the following code to load the MNIST dataset. Then, use the ``show`` function (already implemented) to visualize a digit of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "def show(image):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce training time, we will carry out experiments only on a subset of the dataset. Specifically, the first 10,000 instances of the training set and the first 1,000 instances of the test set will serve as our new training and test sets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:10000,:,:]\n",
    "y_train = y_train[:10000]\n",
    "X_test = X_test[:1000,:,:]\n",
    "y_test = y_test[:1000]\n",
    "\n",
    "print(\"Shape of training matrix:\", X_train.shape)\n",
    "print(\"Shape of test matrix:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the MNIST dataset and reducing its size, it is necessary to reshape all the instances so that their shape is the one a CNN would expect. In Keras, the layers used for two-dimensional convolutions expect the depth of the input image along with its dimensions. In the case of full-color images, the depth is equal to 3 and each dimension corresponds to its red, green and blue components. The images contained in the MNIST dataset are greyscale, hence, the depth is equal to 1. Therefore, to be able to apply two-dimensional convolutions, it is necessary to transform the shape of each image from (width, height) to (depth, width, height). Make use of the [reshape](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.reshape.html) function of NumPy to add an extra dimension to the training and test matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final preprocessing step is to convert the type of the images to float32, normalize their values to the range [0,1] and to encode the class labels using a one-hot scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(\"Shape of training matrix:\", X_train.shape)\n",
    "print(\"Shape of test matrix:\", X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon completing the preprocessing pipeline, we can now start developing the [convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN) architecture. Keras provides rich functionality for building CNNs since it offers various methods for creating convolutional and pooling layers. We first initialize a Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next add a two-dimensional convolution layer to our model. This layer will create a convolution kernel that is convolved with the layer input to produce a tensor of outputs. Use the [`Conv2D`](https://keras.io/layers/convolutional/#conv2d) method of Keras to generate a convolution layer with 32 filters of size (3,3) and a ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a second convolution layer to the model. Set the number of filters to 64 and their size to (2,2). As in the case of the first layer use a ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, define a pooling layer using the [`MaxPooling2D`](https://keras.io/layers/pooling/#maxpooling2d) method of Keras. Max pooling reduces the number of parameters in the model by sliding a 2x2 pooling filter on the output of the previous layer and taking the max of the 4 values in the 2x2 filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next layer is a regularization layer using dropout. Use the [`Dropout`](https://keras.io/layers/core/#dropout) method of Keras to randomly exclude 20% of the neurons in the layer. Dropout has been shown to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next transform the two-dimensional matrix that has emerged from the previous layers to a vector using the [`Flatten`](https://keras.io/layers/core/#flatten) function of Keras. This vector will serve as the input to a standard feedforward neural network. We also create a fully connected layer with 128 neurons and a ReLU activation function. Finally, we add an output layer consisting of 10 neurons for the 10 classes along with a softmax activation function to output probability-like predictions for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next compile the model and by declaring the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adadelta(), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next print a summary representation of the model we generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the neural network and use it to make predictions. Train the model for 10 epochs. Set the batch size to 64. Use the test data as the validation dataset. Once the training has finished, evaluate the model on the test set and print the classification accuracy. Note that training may take several minutes. You can reduce the training time by running the code on a GPU instead of CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer of the neural network we implemented is a convolution layer. This convolution layer is applied directly to the greyscale images of the MNIST dataset, hence, an interesting task is to visualize what these filters have learned. Next, we apply the 32 filters to an image of the training set and we visualize the 26x26 output of each filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def visualize(layer, img):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "\n",
    "    _convout1_f = K.function(inputs, [layer.output])\n",
    "    def convout1_f(X):\n",
    "        return _convout1_f([0] + [X])\n",
    "\n",
    "    convolutions = convout1_f(img)\n",
    "    convolutions = np.squeeze(convolutions)\n",
    "\n",
    "    print ('Shape of conv:', convolutions.shape)\n",
    "    \n",
    "    n = convolutions.shape[2]\n",
    "    n = int(np.ceil(np.sqrt(n)))\n",
    "    \n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    for i in range(convolutions.shape[2]):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[:,:,i], cmap='gray')\n",
    "        \n",
    "# choose an image\n",
    "image = X_train[12,:,:]\n",
    "\n",
    "# Keras requires the image to be in 4D\n",
    "image = np.expand_dims(image, axis=0)\n",
    "        \n",
    "# Specify the layer to want to visualize\n",
    "convout = model.layers[0]\n",
    "visualize(convout, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
