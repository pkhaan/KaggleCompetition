{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1877919",
   "metadata": {},
   "source": [
    "# KAGGLE COMPETITON AUEB 2021-2022\n",
    "## Link Citation Prediction\n",
    "##### Link prediction is the problem of predicting the existence of a link between two entities in a network.\n",
    "\n",
    "The problem of link prediction has recently attracted a lot of attention in many domains. For instance, in social networks, one may be interested in predicting friendship links among users, while in biology, predicting interactions between genes and proteins is of paramount importance.\n",
    "\n",
    "In this challenge, you will deal with the problem of predicting whether a research paper cites another research paper. You are given a citation network consisting of several thousands of research papers, along with their abstracts and their list of authors. The pipeline that is typically followed to deal with the problem is similar to the one applied in any classification problem; the goal is to use edge information to learn the parameters of a classifier and then to use the classifier to predict whether two nodes are linked by an edge or not.\n",
    "\n",
    "Next, we also provide a simple approach, on which you can work. The key component is how we create our training and test data. For training, you may first create a numpy array of zeros with 2m rows and n columns (where m is the number of edges in the edgelist file, and n the number of desired features). We then need to populate this array to create the training features. A way to do that is to iterate over all edges in the edgelist file, and if we want to have 3 features: we get the degree of the first node of the edge as the 1st column, the degree of the 2nd node of the edge as the 2nd column and their sum as the 3rd column. For the remaining m rows, we select randomly nodes and get their degrees and sum as features as well. Now we have our matrix for training. We also need to create the y classes. We create a vector of zeros with size 2m. The first m elements represent the edges that are present in the edgelist. Thus we make them 1. The remaining need to be 0, as they represent non-existing edges. We are now ready to give the features and classes to a scikitlearn classifier via the 'fit' method. Afterwards, we only need to create a similar feature matrix for the test file. We then need the probabilities of our predictions. Remember to get the probabilities only for the positive class. Please, check the 'submissionsrandom' file to check if the format matches your output. The 1st column in the submissions file represents an id integer of the edges in test file. 0 points to the first edge of the test file and so on. You are now ready to submit!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b42235",
   "metadata": {},
   "source": [
    "\t---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13d01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c331146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 138499\n",
      "Number of edges: 1091955\n"
     ]
    }
   ],
   "source": [
    "# Create a graph\n",
    "G = nx.read_edgelist('data/edgelist.txt', delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
    "nodes = list(G.nodes())\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "print('Number of nodes:', n)\n",
    "print('Number of edges:', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7820b0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read the abstract of each paper\n",
    "abstracts = dict()\n",
    "\n",
    "with open('data/abstracts.txt', 'r', encoding = \"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        node, abstract = line.split('|--|')\n",
    "        \n",
    "        abstracts[int(node)] = abstract\n",
    "\n",
    "for node in abstracts:\n",
    "    abstracts[node] = set(abstracts[node].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1598fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = dict()\n",
    "with open('data/authors.txt', 'r', encoding = \"UTF-8\") as f:\n",
    "    for line in f:\n",
    "        node, author = line.split('|--|')\n",
    "        \n",
    "        authors[int(node)] = author.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "141638c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list_1 = []\n",
    "node_list_2 = []\n",
    "\n",
    "for i in G.edges:\n",
    "  node_list_1.append(i[0])\n",
    "  node_list_2.append(i[1])\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'node_1': node_list_1, 'node_2': node_list_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3991ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "G = nx.from_pandas_edgelist(df, \"node_1\", \"node_2\", create_using=nx.Graph())\n",
    "# plot graph\n",
    "plt.figure(figsize=(10,10))\n",
    "pos = nx.random_layout(G, seed=23)\n",
    "nx.draw(G, with_labels=False,  pos = pos, node_size = 40, alpha = 0.6, width = 0.7)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# its class label is 1 if it corresponds to an edge and 0, otherwise.\n",
    "# Use the following 3 features for each pair of nodes:\n",
    "# (1) sum of number of unique terms of the two nodes' abstracts\n",
    "# (2) absolute value of difference of number of unique terms of the two nodes' abstracts\n",
    "# (3) number of common terms between the abstracts of the two nodes\n",
    "\n",
    "x = np.zeros((2*m, 4))\n",
    "y = np.zeros(2*m)\n",
    "n = G.number_of_nodes()\n",
    "for i,edge in enumerate(G.edges()):\n",
    "    # an edge\n",
    "    x[i,0] = len(abstracts[edge[0]]) + len(abstracts[edge[1]])\n",
    "    x[i,1] = abs(len(abstracts[edge[0]]) - len(abstracts[edge[1]]))\n",
    "    x[i,2] = len(abstracts[edge[0]].intersection(abstracts[edge[1]]))\n",
    "    x[i,3] = len(set(authors[edge[0]]).intersection(authors[edge[1]]))\n",
    "    y[i] = 1\n",
    "\n",
    "    # a randomly generated pair of nodes\n",
    "    n1 = randint(0, n-1)\n",
    "    n2 = randint(0, n-1)\n",
    "    x[m+i,0] = len(abstracts[n1]) + len(abstracts[n2])\n",
    "    x[m+i,1] = abs(len(abstracts[n1]) - len(abstracts[n2]))\n",
    "    x[m+i,2] = len(abstracts[n1].intersection(abstracts[n2]))\n",
    "    x[m+i,3] = len(set(authors[n1]).intersection(authors[n2]))\n",
    "    y[m+i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbaf0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = shuffle(x, y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa484736",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use logistic regression to predict if two nodes are linked by an edge\n",
    "clf = LogisticRegression(solver='liblinear',random_state=34)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict_proba(x_test)\n",
    "y_pred = y_pred[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f5eab",
   "metadata": {},
   "source": [
    "##### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda9bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef881db3",
   "metadata": {},
   "source": [
    "##### Ada-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790af812",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "\n",
    "model = abc.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7201781",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = []\n",
    "for i in y_pred: \n",
    "    if i >= 0.5: \n",
    "        y_predictions.append(1)\n",
    "    else:\n",
    "        y_predictions.append(0)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa6ca6",
   "metadata": {},
   "source": [
    "##### Graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
